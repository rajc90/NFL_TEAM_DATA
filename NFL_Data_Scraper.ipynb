{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NFL Data Scraping Project\n",
    "This is a notebook that will describe the web scraping process for NFL team statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we need to figure out what information and where to find that information. For this project I want to analyze how regular season statistics for a team impact their performance during the regular season and in the playoffs.\n",
    "- To find the regular season statistics I will be using the information provided by the NFL here: **https://www.nfl.com/stats/team-stats/**\n",
    "- To find the win and loss information for teams I used information from this link: **https://www.teamrankings.com/nfl/trends/win_trends/**\n",
    "\n",
    "Let's start by gathering the win loss data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages\n",
    "For this project I will be using selenium and using beautiful soup to conduct web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from requests_html import HTMLSession\n",
    "from urllib.parse import urljoin\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.teamrankings.com/nfl/trends/win_trends/?sc=is_regular_season\"\n",
    "response = r.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "specific_div = soup.find('table') # finding the table with the record of each team\n",
    "rows = specific_div.find_all('tr') # get the rows of data\n",
    "\n",
    "# Now that we have the data as a list of rows, we can parse the data to construct a data frame\n",
    "data = []\n",
    "for row in rows:\n",
    "        cells = row.find_all(['td', 'th'])  # 'td' for regular cells, 'th' for header cells\n",
    "        row_data = [cell.text.strip() for cell in cells] #extract the contents in each cell\n",
    "        data.append(row_data)\n",
    "columns = data[0]\n",
    "df = pd.DataFrame(data[1:], columns=columns)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now parsed the data for 1 year. The next challenge is to change the filters to get postseason data, and then to change the year filter to get data for each year. When inspecting the html code we can see that there a 'div class=filter' which holds the different filter that we can change. When a year filter is changed the url changes. For examples *https://www.teamrankings.com/nfl/trends/win_trends/?sc=is_regular_season&range=yearly_2022&range=yearly_2022*. Using the final parameter \"&range=yearly_2022\" we can adjust the url to select the year to scrape the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.teamrankings.com/nfl/trends/win_trends/?sc=is_regular_season&range=yearly_2022&range=yearly_2022\n"
     ]
    }
   ],
   "source": [
    "url = url + v\n",
    "year = 2022\n",
    "url = url + str(year)\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the goal is to create a function of the above code, and iterate through each year to pull data. Note that for the data to be scraped, we want a full year of data. As of this time the 2023 season is going on, so we will look to pull data up to 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(year):\n",
    "    # Reads the data from the website extracting the values of the table based on the year\n",
    "    # Param: year - year of data to be collected\n",
    "\n",
    "    url = \"https://www.teamrankings.com/nfl/trends/win_trends/?sc=is_regular_season&range=yearly_\"\n",
    "    url = url + year\n",
    "    response = r.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    specific_div = soup.find('table') # finding the table with the record of each team\n",
    "    rows = specific_div.find_all('tr') # get the rows of data\n",
    "\n",
    "    # Now that we have the data as a list of rows, we can parse the data to construct a data frame\n",
    "    data = []\n",
    "    for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])  # 'td' for regular cells, 'th' for header cells\n",
    "            row_data = [cell.text.strip() for cell in cells] #extract the contents in each cell\n",
    "            data.append(row_data)\n",
    "    columns = data[0]\n",
    "    df = pd.DataFrame(data[1:], columns=columns)\n",
    "read_data(\"2003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have made a function, we want to have 1 table with data from all possible years. To do this we need to identify each data point by year. Therefore we need to adjust our original function to add column for year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Win-Loss Record</th>\n",
       "      <th>Win %</th>\n",
       "      <th>MOV</th>\n",
       "      <th>ATS +/-</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>15-1-0</td>\n",
       "      <td>93.8%</td>\n",
       "      <td>7.6</td>\n",
       "      <td>+4.8</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New England</td>\n",
       "      <td>14-2-0</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>11.1</td>\n",
       "      <td>+4.2</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>13-3-0</td>\n",
       "      <td>81.3%</td>\n",
       "      <td>7.9</td>\n",
       "      <td>+1.8</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>10.7</td>\n",
       "      <td>+5.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LA Chargers</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>8.3</td>\n",
       "      <td>+9.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Atlanta</td>\n",
       "      <td>11-5-0</td>\n",
       "      <td>68.8%</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NY Jets</td>\n",
       "      <td>10-6-0</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>4.5</td>\n",
       "      <td>+2.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Green Bay</td>\n",
       "      <td>10-6-0</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>2.8</td>\n",
       "      <td>+0.8</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Denver</td>\n",
       "      <td>10-6-0</td>\n",
       "      <td>62.5%</td>\n",
       "      <td>4.8</td>\n",
       "      <td>+0.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>9-7-0</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Buffalo</td>\n",
       "      <td>9-7-0</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>6.9</td>\n",
       "      <td>+6.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Baltimore</td>\n",
       "      <td>9-7-0</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>3.1</td>\n",
       "      <td>+1.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>9-7-0</td>\n",
       "      <td>56.3%</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cincinnati</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>0.1</td>\n",
       "      <td>+2.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Minnesota</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LA Rams</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>New Orleans</td>\n",
       "      <td>8-8-0</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Carolina</td>\n",
       "      <td>7-9-0</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>1.0</td>\n",
       "      <td>+1.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>7-9-0</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>3.0</td>\n",
       "      <td>+1.6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Houston</td>\n",
       "      <td>7-9-0</td>\n",
       "      <td>43.8%</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>+1.5</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Washington</td>\n",
       "      <td>6-10-0</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>6-10-0</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>+1.5</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>6-10-0</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NY Giants</td>\n",
       "      <td>6-10-0</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>6-10-0</td>\n",
       "      <td>37.5%</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>5-11-0</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>5-11-0</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tampa Bay</td>\n",
       "      <td>5-11-0</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>+0.5</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>5-11-0</td>\n",
       "      <td>31.3%</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Cleveland</td>\n",
       "      <td>4-12-0</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>-7.1</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Miami</td>\n",
       "      <td>4-12-0</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>2-14-0</td>\n",
       "      <td>12.5%</td>\n",
       "      <td>-12.1</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Team Win-Loss Record  Win %    MOV ATS +/-  Year\n",
       "0      Pittsburgh          15-1-0  93.8%    7.6    +4.8  2004\n",
       "1     New England          14-2-0  87.5%   11.1    +4.2  2004\n",
       "2    Philadelphia          13-3-0  81.3%    7.9    +1.8  2004\n",
       "3    Indianapolis          12-4-0  75.0%   10.7    +5.4  2004\n",
       "4     LA Chargers          12-4-0  75.0%    8.3    +9.0  2004\n",
       "5         Atlanta          11-5-0  68.8%    0.2    -2.0  2004\n",
       "6         NY Jets          10-6-0  62.5%    4.5    +2.3  2004\n",
       "7       Green Bay          10-6-0  62.5%    2.8    +0.8  2004\n",
       "8          Denver          10-6-0  62.5%    4.8    +0.1  2004\n",
       "9         Seattle           9-7-0  56.3%   -0.1    -3.8  2004\n",
       "10        Buffalo           9-7-0  56.3%    6.9    +6.4  2004\n",
       "11      Baltimore           9-7-0  56.3%    3.1    +1.1  2004\n",
       "12   Jacksonville           9-7-0  56.3%   -1.2    -0.1  2004\n",
       "13     Cincinnati           8-8-0  50.0%    0.1    +2.3  2004\n",
       "14      Minnesota           8-8-0  50.0%    0.6    -3.2  2004\n",
       "15        LA Rams           8-8-0  50.0%   -4.6    -6.5  2004\n",
       "16    New Orleans           8-8-0  50.0%   -3.6    -0.9  2004\n",
       "17       Carolina           7-9-0  43.8%    1.0    +1.4  2004\n",
       "18    Kansas City           7-9-0  43.8%    3.0    +1.6  2004\n",
       "19        Houston           7-9-0  43.8%   -1.9    +1.5  2004\n",
       "20     Washington          6-10-0  37.5%   -1.6    -0.3  2004\n",
       "21        Arizona          6-10-0  37.5%   -2.4    +1.5  2004\n",
       "22         Dallas          6-10-0  37.5%   -7.0    -5.4  2004\n",
       "23      NY Giants          6-10-0  37.5%   -2.8    -0.1  2004\n",
       "24        Detroit          6-10-0  37.5%   -3.4    -1.4  2004\n",
       "25      Tennessee          5-11-0  31.3%   -5.9    -5.9  2004\n",
       "26        Chicago          5-11-0  31.3%   -6.3    -1.8  2004\n",
       "27      Tampa Bay          5-11-0  31.3%   -0.2    +0.5  2004\n",
       "28      Las Vegas          5-11-0  31.3%   -7.6    -4.9  2004\n",
       "29      Cleveland          4-12-0  25.0%   -7.1    -1.6  2004\n",
       "30          Miami          4-12-0  25.0%   -4.9    -0.2  2004\n",
       "31  San Francisco          2-14-0  12.5%  -12.1    -6.4  2004"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_data(year):\n",
    "    # Reads the data from the website extracting the values of the table based on the year\n",
    "    # Param: year - year of data to be collected\n",
    "\n",
    "    url = \"https://www.teamrankings.com/nfl/trends/win_trends/?sc=is_regular_season&range=yearly_\"\n",
    "    url = url + str(year)\n",
    "    response = r.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    specific_div = soup.find('table') # finding the table with the record of each team\n",
    "    rows = specific_div.find_all('tr') # get the rows of data\n",
    "\n",
    "    # Now that we have the data as a list of rows, we can parse the data to construct a data frame\n",
    "    data = []\n",
    "    for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])  # 'td' for regular cells, 'th' for header cells\n",
    "            row_data = [cell.text.strip() for cell in cells] #extract the contents in each cell\n",
    "            data.append(row_data)\n",
    "    columns = data[0]\n",
    "    df = pd.DataFrame(data[1:], columns=columns)\n",
    "    df[\"Year\"] = year #helps identify the data points based on year\n",
    "    return df\n",
    "read_data(\"2004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can identify the year for each data table, we need to loop through each year and pull the data for the regular season. To get the data for years, the __datetime__ package will be used to always get the current year. We will loop through years from 2003 to the year before the current year. All of this data will then be placed into 1 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team</th>\n",
       "      <th>Win-Loss Record</th>\n",
       "      <th>Win %</th>\n",
       "      <th>MOV</th>\n",
       "      <th>ATS +/-</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New England</td>\n",
       "      <td>14-2-0</td>\n",
       "      <td>87.5%</td>\n",
       "      <td>6.9</td>\n",
       "      <td>+5.1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kansas City</td>\n",
       "      <td>13-3-0</td>\n",
       "      <td>81.3%</td>\n",
       "      <td>9.5</td>\n",
       "      <td>+3.7</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>5.4</td>\n",
       "      <td>+3.1</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tennessee</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>6.9</td>\n",
       "      <td>+3.0</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>12-4-0</td>\n",
       "      <td>75.0%</td>\n",
       "      <td>6.9</td>\n",
       "      <td>+3.4</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LA Rams</td>\n",
       "      <td>5-12-0</td>\n",
       "      <td>29.4%</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>4-12-1</td>\n",
       "      <td>25.0%</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>4-13-0</td>\n",
       "      <td>23.5%</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Houston</td>\n",
       "      <td>3-13-1</td>\n",
       "      <td>18.8%</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>3-14-0</td>\n",
       "      <td>17.7%</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>640 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Team Win-Loss Record  Win %   MOV ATS +/-  Year\n",
       "0    New England          14-2-0  87.5%   6.9    +5.1  2003\n",
       "1    Kansas City          13-3-0  81.3%   9.5    +3.7  2003\n",
       "2   Philadelphia          12-4-0  75.0%   5.4    +3.1  2003\n",
       "3      Tennessee          12-4-0  75.0%   6.9    +3.0  2003\n",
       "4   Indianapolis          12-4-0  75.0%   6.9    +3.4  2003\n",
       "..           ...             ...    ...   ...     ...   ...\n",
       "27       LA Rams          5-12-0  29.4%  -4.5    -3.0  2022\n",
       "28  Indianapolis          4-12-1  25.0%  -8.1    -6.6  2022\n",
       "29       Arizona          4-13-0  23.5%  -6.4    -2.5  2022\n",
       "30       Houston          3-13-1  18.8%  -7.7    -0.4  2022\n",
       "31       Chicago          3-14-0  17.7%  -8.1    -3.0  2022\n",
       "\n",
       "[640 rows x 6 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "all_data = []\n",
    "current_year = int(dt.datetime.today().strftime(\"%Y\"))\n",
    "for i in range(2003, current_year):\n",
    "    x = read_data(i)\n",
    "    all_data.append(x) # adding data frame objects to a list\n",
    "\n",
    "regular_seasonn_data = pd.concat(all_data) # using pandas concat function which is more efficient than for loop\n",
    "regular_seasonn_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the regular season win loss information, we can adjust our function to get information about the playoff games. We can do this by adding a parameter for the type of game we want to search for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(year, game_type):\n",
    "    # Reads the data from the website extracting the values of the table based on the year\n",
    "    # Param: year - year of data to be collected\n",
    "\n",
    "    url = f\"https://www.teamrankings.com/nfl/trends/win_trends/?sc={game_type}&range=yearly_\"\n",
    "    url = url + str(year)\n",
    "    response = r.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    specific_div = soup.find('table') # finding the table with the record of each team\n",
    "    rows = specific_div.find_all('tr') # get the rows of data\n",
    "\n",
    "    # Now that we have the data as a list of rows, we can parse the data to construct a data frame\n",
    "    data = []\n",
    "    for row in rows:\n",
    "            cells = row.find_all(['td', 'th'])  # 'td' for regular cells, 'th' for header cells\n",
    "            row_data = [cell.text.strip() for cell in cells] #extract the contents in each cell\n",
    "            data.append(row_data)\n",
    "    columns = data[0]\n",
    "    df = pd.DataFrame(data[1:], columns=columns)\n",
    "    df[\"Year\"] = year #helps identify the data points based on year\n",
    "    return df\n",
    "read_data(\"2004\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
